[
    {
        "abstract": "We use public data from the CMS experiment to study the 2-prong substructure\nof jets. The CMS Open Data is based on 31.8/pb of 7 TeV proton-proton\ncollisions recorded at the Large Hadron Collider in 2010, yielding a sample of\n768,687 events containing a high-quality central jet with transverse momentum\nlarger than 85 GeV. Using CMS's particle flow reconstruction algorithm to\nobtain jet constituents, we extract the 2-prong substructure of the leading jet\nusing soft drop declustering. We find good agreement between results obtained\nfrom the CMS Open Data and those obtained from parton shower generators, and we\nalso compare to analytic jet substructure calculations performed to modified\nleading-logarithmic accuracy. Although the 2010 CMS Open Data does not include\nsimulated data to help estimate systematic uncertainties, we use track-only\nobservables to validate these substructure studies.",
        "date": "2017-04-19",
        "doi": "http://dx.doi.org/10.1103/PhysRevD.96.074003",
        "title": "Jet Substructure Studies with CMS Open Data",
        "url": "http://arxiv.org/abs/1704.05842v3"
    },
    {
        "abstract": "The CMS Open Data project offers new opportunities to measure cross sections\nof standard model (SM) processes which have not been probed so far. In this\nwork, we evaluate the challenges and the opportunities of the CMS Open Data\nproject in the view of cross-section measurements. In particular, we reevaluate\nSM cross sections of the production of W bosons, Z bosons, top-quark pairs and\nWZ dibosons in several decay channels at a center of mass energy of 8 TeV with\na corresponding integrated luminosity of 1.8 fb-1. Those cross sections have\nbeen previously measured by the ATLAS and CMS collaborations and hence can be\nused to validate our analysis and calibration strategy. This gives an\nindication to which precision also new, so far unmeasured cross sections can be\ndetermined using CMS Open Data by scientists, who are not a member of the LHC\ncollaborations and hence lack detailed knowledge on experimental and detector\nrelated effects and their handling.",
        "date": "2019-07-18",
        "doi": "http://dx.doi.org/10.1088/1748-0221/15/01/P01009",
        "title": "Opportunities and Challenges of Standard Model Production Cross Section\n  Measurements at 8 TeV using CMS Open Data",
        "url": "http://arxiv.org/abs/1907.08197v2"
    },
    {
        "abstract": "A cluster of soft displaced tracks corresponds to the dark matter\nco-annihilation regime. The long-lived regime is, in particular, motivated by\nthe unexplored top partner physics. The background in this regime is extremely\nchallenging to model using a traditional simulation method. We demonstrate the\nfeasibility of handling the formidable background using the CMS Open Data. We\nperform this analysis to search for compressed and long-lived top partners in\nthe 8 TeV CMS Open Data events with the integrated luminosity of 11.6 fb$^{-1}$\nand obtain new limits. With 15-30 GeV mass splitting between the top partner\nand the DM candidate, we exclude the top partner mass below 350 GeV, which is\nmore stringent than the ATLAS and CMS results using 8 TeV data with 20\nfb$^{-1}$ luminosity. Our study also shows that the CMS Open Data can be a\npowerful tool to help physicists explore non-conventional new physics and even\nenable deriving new limits on exotic signals from data directly.",
        "date": "2021-07-23",
        "doi": "http://arxiv.org/abs/2107.11405v1",
        "title": "Exploring Uncharted Soft Displaced Vertices in Open Data",
        "url": "http://arxiv.org/abs/2107.11405v1"
    },
    {
        "abstract": "We study dimuon events in 2.11/fb of 7 TeV pp collisions, using CMS Open\nData, and search for a narrow dimuon resonance with moderate mass (14-66 GeV)\nand substantial transverse momentum (pT). Applying dimuon pT cuts of 25 GeV and\n60 GeV, we explore two overlapping samples: one with isolated muons, and one\nwith prompt muons without an isolation requirement. Using the latter sample\nrequires information about detector effects and QCD backgrounds, which we\nobtain directly from the CMS Open Data. We present model-independent limits on\nthe product of cross section, branching fraction, acceptance, and efficiencies.\nThese limits are stronger, relative to a corresponding inclusive search without\na pT cut, by factors of as much as nine. Our \"pT-enhanced\" dimuon search\nstrategy provides improved sensitivity to models in which a new particle is\nproduced mainly in the decay of something heavier, as could occur, for example,\nin decays of the Higgs boson or of a TeV-scale top partner. An implementation\nof this method with the current 13 TeV data should improve the sensitivity to\nsuch signals further by roughly an order of magnitude.",
        "date": "2019-02-12",
        "doi": "http://dx.doi.org/10.1103/PhysRevD.100.015021",
        "title": "Searching in CMS Open Data for Dimuon Resonances with Substantial\n  Transverse Momentum",
        "url": "http://arxiv.org/abs/1902.04222v2"
    },
    {
        "abstract": "We explore the metric space of jets using public collider data from the CMS\nexperiment. Starting from 2.3/fb of 7 TeV proton-proton collisions collected at\nthe Large Hadron Collider in 2011, we isolate a sample of 1,690,984 central\njets with transverse momentum above 375 GeV. To validate the performance of the\nCMS detector in reconstructing the energy flow of jets, we compare the CMS Open\nData to corresponding simulated data samples for a variety of jet kinematic and\nsubstructure observables. Even without detector unfolding, we find very good\nagreement for track-based observables after using charged hadron subtraction to\nmitigate the impact of pileup. We perform a range of novel analyses, using the\n\"energy mover's distance\" (EMD) to measure the pairwise difference between jet\nenergy flows. The EMD allows us to quantify the impact of detector effects,\nvisualize the metric space of jets, extract correlation dimensions, and\nidentify the most and least typical jet configurations. To facilitate future\njet studies with CMS Open Data, we make our datasets and analysis code\navailable, amounting to around two gigabytes of distilled data and one hundred\ngigabytes of simulation files.",
        "date": "2019-08-22",
        "doi": "http://dx.doi.org/10.1103/PhysRevD.101.034009",
        "title": "Exploring the Space of Jets with CMS Open Data",
        "url": "http://arxiv.org/abs/1908.08542v2"
    },
    {
        "abstract": "We describe a novel application of the end-to-end deep learning technique to\nthe task of discriminating top quark-initiated jets from those originating from\nthe hadronization of a light quark or a gluon. The end-to-end deep learning\ntechnique combines deep learning algorithms and low-level detector\nrepresentation of the high-energy collision event. In this study, we use\nlow-level detector information from the simulated CMS Open Data samples to\nconstruct the top jet classifiers. To optimize classifier performance we\nprogressively add low-level information from the CMS tracking detector,\nincluding pixel detector reconstructed hits and impact parameters, and\ndemonstrate the value of additional tracking information even when no new\nspatial structures are added. Relying only on calorimeter energy deposits and\nreconstructed pixel detector hits, the end-to-end classifier achieves an AUC\nscore of 0.975$\\pm$0.002 for the task of classifying boosted top quark jets.\nAfter adding derived track quantities, the classifier AUC score increases to\n0.9824$\\pm$0.0013, serving as the first performance benchmark for these CMS\nOpen Data samples. We additionally provide a timing performance comparison of\ndifferent processor unit architectures for training the network.",
        "date": "2021-04-19",
        "doi": "http://dx.doi.org/10.1103/PhysRevD.105.052008",
        "title": "End-to-End Jet Classification of Boosted Top Quarks with the CMS Open\n  Data",
        "url": "http://arxiv.org/abs/2104.14659v3"
    },
    {
        "abstract": "The splitting function is a universal property of quantum chromodynamics\n(QCD) which describes how energy is shared between partons. Despite its\nubiquitous appearance in many QCD calculations, the splitting function cannot\nbe measured directly since it always appears multiplied by a collinear\nsingularity factor. Recently, however, a new jet substructure observable was\nintroduced which asymptotes to the splitting function for sufficiently high jet\nenergies. This provides a way to expose the splitting function through jet\nsubstructure measurements at the Large Hadron Collider. In this letter, we use\npublic data released by the CMS experiment to study the 2-prong substructure of\njets and test the 1 -> 2 splitting function of QCD. To our knowledge, this is\nthe first ever physics analysis based on the CMS Open Data.",
        "date": "2017-04-17",
        "doi": "http://dx.doi.org/10.1103/PhysRevLett.119.132003",
        "title": "Exposing the QCD Splitting Function with CMS Open Data",
        "url": "http://arxiv.org/abs/1704.05066v3"
    },
    {
        "abstract": "This paper describes the construction of novel end-to-end image-based\nclassifiers that directly leverage low-level simulated detector data to\ndiscriminate signal and background processes in pp collision events at the\nLarge Hadron Collider at CERN. To better understand what end-to-end classifiers\nare capable of learning from the data and to address a number of associated\nchallenges, we distinguish the decay of the standard model Higgs boson into two\nphotons from its leading background sources using high-fidelity simulated CMS\nOpen Data. We demonstrate the ability of end-to-end classifiers to learn from\nthe angular distribution of the photons recorded as electromagnetic showers,\ntheir intrinsic shapes, and the energy of their constituent hits, even when the\nunderlying particles are not fully resolved, delivering a clear advantage in\nsuch cases over purely kinematics-based classifiers.",
        "date": "2018-07-31",
        "doi": "http://dx.doi.org/10.1007/s41781-020-00038-8",
        "title": "End-to-End Physics Event Classification with CMS Open Data: Applying\n  Image-Based Deep Learning to Detector Data for the Direct Classification of\n  Collision Events at the LHC",
        "url": "http://arxiv.org/abs/1807.11916v3"
    },
    {
        "abstract": "The underlying event is an important part of high-energy collision events. In\nthe event generators, the underlying event is tuned by fits to collision data.\nUsually, the underlying event observables are affected by the existence of\nextra jets and it is difficult to find a part of the phase space which is\ndominated by the underlying event. In this paper, we suggest to veto the jets\nin the considered region to disentangle these effects. The idea is verified to\nwork on CMS Open Data. To our knowledge, it is the first time that such ideas\nare tested on real collision data.",
        "date": "2019-07-20",
        "doi": "http://dx.doi.org/10.1088/1361-6471/ab33a9",
        "title": "Explicit Jet Veto as a Tool to Purify the Underlying Event in the\n  Drell-Yan Process Using CMS Open Data",
        "url": "http://arxiv.org/abs/1907.08842v1"
    },
    {
        "abstract": "We describe the construction of end-to-end jet image classifiers based on\nsimulated low-level detector data to discriminate quark- vs. gluon-initiated\njets with high-fidelity simulated CMS Open Data. We highlight the importance of\nprecise spatial information and demonstrate competitive performance to existing\nstate-of-the-art jet classifiers. We further generalize the end-to-end approach\nto event-level classification of quark vs. gluon di-jet QCD events. We compare\nthe fully end-to-end approach to using hand-engineered features and demonstrate\nthat the end-to-end algorithm is robust against the effects of underlying event\nand pile-up.",
        "date": "2019-02-21",
        "doi": "http://dx.doi.org/10.1016/j.nima.2020.164304",
        "title": "End-to-End Jet Classification of Quarks and Gluons with the CMS Open\n  Data",
        "url": "http://arxiv.org/abs/1902.08276v2"
    },
    {
        "abstract": "We apply an Adversarially Learned Anomaly Detection (ALAD) algorithm to the\nproblem of detecting new physics processes in proton-proton collisions at the\nLarge Hadron Collider. Anomaly detection based on ALAD matches performances\nreached by Variational Autoencoders, with a substantial improvement in some\ncases. Training the ALAD algorithm on 4.4 fb-1 of 8 TeV CMS Open Data, we show\nhow a data-driven anomaly detection and characterization would work in real\nlife, re-discovering the top quark by identifying the main features of the\nt-tbar experimental signature at the LHC.",
        "date": "2020-05-04",
        "doi": "http://arxiv.org/abs/2005.01598v2",
        "title": "Adversarially Learned Anomaly Detection on CMS Open Data: re-discovering\n  the top quark",
        "url": "http://arxiv.org/abs/2005.01598v2"
    },
    {
        "abstract": "In this work, we present a search for the possible production of Dark Matter\nparticles at the Large Hadron Collider alongside a new hypothetical gauge boson\ndenoted by Z$^{\\prime}$, which is governed by a model called Mono-Z$^{\\prime}$.\nThe topology of the studied events is dimuons plus large missing transverse\nmomentum. The analyzed data were the CMS open data samples collected by the CMS\ndetector, in addition to the CMS open Monte Carlo samples, for the\nproton-proton collisions at 8 TeV center of mass energy during 2012, which\ncorrespond to an integrated luminosity of 11.6 fb$^{-1}$. Two benchmarks\nscenarios were used for interpreting the data, the Dark Higgs scenario as a\nsimplified scenario of the Mono-Z$^{\\prime}$ model and the effective field\ntheory formalism of the same model. No evidence for the existence of dark\nmatter candidates was found. Consequently, 95$\\%$ confidence level limits were\nset on the masses of the Z$^{\\prime}$ and the cutoff scale of the effective\nfield theory.",
        "date": "2021-09-23",
        "doi": "http://arxiv.org/abs/2109.11274v3",
        "title": "Search for the production of dark matter candidates in association with\n  heavy dimuon resonance using the CMS open data for pp collisions at\n  $\\sqrt{s}$ = 8 TeV",
        "url": "http://arxiv.org/abs/2109.11274v3"
    },
    {
        "abstract": "In recent years novel inference techniques have been developed based on the\nconstruction of non-linear summary statistics with neural networks by\nminimising inferencemotivated losses. One such technique is inferno (P. de\nCastro and T. Dorigo, Comp. Phys. Comm. 244 (2019) 170) which was shown on toy\nproblems to outperform classical summary statistics for the problem of\nconfidence interval estimation in the presence of nuisance parameters. In order\nto test and benchmark the algorithm in a real world application, a full,\nsystematics-dominated analysis produced by the CMS experiment, \"Measurement of\nthe top-antitop production cross section in the tau+jets channel in pp\ncollisions at sqrt(s) = 7 TeV\" (CMS Collaboration, The European Physical\nJournal C, 2013) is reproduced with CMS Open Data. The application of the\ninferno-powered neural network architecture to this analysis demonstrates the\npotential to reduce the impact of systematic uncertainties in real LHC\nanalyses. This work also exemplifies the extent to which LHC analyses can be\nreproduced with open data.",
        "date": "2023-01-25",
        "doi": "http://arxiv.org/abs/2301.10358v1",
        "title": "Application of Inferno to a Top Pair Cross Section Measurement with CMS\n  Open Data",
        "url": "http://arxiv.org/abs/2301.10358v1"
    },
    {
        "abstract": "We use the CMS Open Data to examine the performance of weakly-supervised\nlearning for tagging quark and gluon jets at the LHC. We target $Z$+jet and\ndijet events as respective quark- and gluon-enriched mixtures and derive\nsamples both from data taken in 2011 at 7 TeV, and from Monte Carlo. CWoLa and\nTopicFlow models are trained on real data and compared to fully-supervised\nclassifiers trained on simulation. In order to obtain estimates for the\ndiscrimination power in real data, we consider three different estimates of the\nquark/gluon mixture fractions in the data. Compared to when the models are\nevaluated on simulation, we find reversed rankings for the fully- and\nweakly-supervised approaches. Further, these rankings based on data are robust\nto the estimate of the mixture fraction in the test set. Finally, we use\nTopicFlow to smooth statistical fluctuations in the small testing set, and to\nprovide uncertainty on the performance in real data.",
        "date": "2023-12-06",
        "doi": "http://arxiv.org/abs/2312.03434v1",
        "title": "Quark-versus-gluon tagging in CMS Open Data with CWoLa and TopicFlow",
        "url": "http://arxiv.org/abs/2312.03434v1"
    },
    {
        "abstract": "The CMS experiment at CERN has released research-quality data from particle\ncollisions at the LHC since 2014. Almost all data from the first LHC run in\n2010-2012 with the corresponding simulated samples are now in the public\ndomain, and several scientific studies have been performed using these data.\nThis paper summarizes the available data and tools, reviews the challenges in\nusing them in research, and discusses measures to improve their usability.",
        "date": "2021-06-10",
        "doi": "http://dx.doi.org/10.1051/epjconf/202125101004",
        "title": "Using CMS Open Data in research -- challenges and directions",
        "url": "http://arxiv.org/abs/2106.05726v1"
    },
    {
        "abstract": "Reliable modeling of conditional densities is important for quantitative\nscientific fields such as particle physics. In domains outside physics,\nimplicit quantile neural networks (IQN) have been shown to provide accurate\nmodels of conditional densities. We present a successful application of IQNs to\njet simulation and correction using the tools and simulated data from the\nCompact Muon Solenoid (CMS) Open Data portal.",
        "date": "2021-11-22",
        "doi": "http://arxiv.org/abs/2111.11415v1",
        "title": "Implicit Quantile Neural Networks for Jet Simulation and Correction",
        "url": "http://arxiv.org/abs/2111.11415v1"
    },
    {
        "abstract": "The Standard Model violates parity, but only by mechanisms which are\ninvisible to Large Hadron Collider (LHC) experiments (on account of the lack of\ninitial state polarisation or spin-sensitivity in the detectors). Nonetheless,\nnew physical processes could potentially violate parity in ways which are\ndetectable by those same experiments. If those sources of new physics occur\nonly at LHC energies, they are untested by direct searches. We probe the\nfeasibility of such measurements using approximately 0.2 inverse femtobarns of\ndata which was recorded in 2012 by the CMS collaboration and made public within\nthe CMS Open Data initiative. In particular, we test an inclusive three-jet\nevent selection which is primarily sensitive to non-standard parity violating\neffects in quark-gluon interactions. Within our measurements, no significant\ndeviation from the Standard Model is seen and no obvious experimental\nlimitations have been found. We discuss other ways that searches for\nnon-standard parity violation could be performed, noting that these would be\nsensitive to very different sorts of models to those which our measurements\nconstrain. We hope that our initial studies provide a valuable starting point\nfor rigorous future analyses using the full LHC datasets at 13 TeV with a\ncareful and less conservative estimate of experimental uncertainties.",
        "date": "2019-04-25",
        "doi": "http://dx.doi.org/10.1007/JHEP12(2019)120",
        "title": "Search for Non-Standard Sources of Parity Violation in Jets at $\\sqrt\n  s$=8 TeV with CMS Open Data",
        "url": "http://arxiv.org/abs/1904.11195v4"
    },
    {
        "abstract": "From particle identification to the discovery of the Higgs boson, deep\nlearning algorithms have become an increasingly important tool for data\nanalysis at the Large Hadron Collider (LHC). We present an innovative\nend-to-end deep learning approach for jet identification at the Compact Muon\nSolenoid (CMS) experiment at the LHC. The method combines deep neural networks\nwith low-level detector information, such as calorimeter energy deposits and\ntracking information, to build a discriminator to identify different particle\nspecies. Using two physics examples as references: electron vs. photon\ndiscrimination and quark vs. gluon discrimination, we demonstrate the\nperformance of the end-to-end approach on simulated events with full detector\ngeometry as available in the CMS Open Data. We also offer insights into the\nimportance of the information extracted from various sub-detectors and describe\nhow end-to-end techniques can be extended to event-level classification using\ninformation from the whole CMS detector.",
        "date": "2019-10-15",
        "doi": "http://arxiv.org/abs/1910.07029v1",
        "title": "End-to-end particle and event identification at the Large Hadron\n  Collider with CMS Open Data",
        "url": "http://arxiv.org/abs/1910.07029v1"
    },
    {
        "abstract": "The ultralight boson represents a promising dark matter candidate exhibiting\nunique wave-like behaviors. These properties could transfer to the dark\nmediator, such as the kinetic mixing dark photon, which can be a link between\nthe dark and Standard Model sectors, resulting in periodic oscillations of its\nmass. We propose a method to detect ultralight dark matter using dark mediators\nin collider and beam dump experiments, distinguishing it from conventional\natomic, molecular, and optical methods. The time-varying nature of dark\nmediator mass exhibits a double-peak spectrum, reducing traditional constraints\nby 1 to 2 orders of magnitude, due to decreased luminosity exposure in each\nresonant mass bin. To enhance sensitivity, we utilize event time-stamps in the\nCMS Open Data and demonstrate that this technique boosts sensitivity by\napproximately one order of magnitude compared to the time-blind method.\nMoreover, it proves effective in detecting the invisible decay of the dark\nmediator.",
        "date": "2022-06-28",
        "doi": "http://dx.doi.org/10.1038/s42005-023-01350-6",
        "title": "Unveiling Time-Varying Signals of Ultralight Bosonic Dark Matter at\n  Collider and Beam Dump Experiments",
        "url": "http://arxiv.org/abs/2206.14221v3"
    },
    {
        "abstract": "This analysis shows a search for dark fermion particles produced in\nassociation with a heavy neutral gauge boson (Z$^{\\prime}$). The studied events\ntopology are dimuon and a large missing transverse momentum. %We considered the\nmuonic decay of Z$^{\\prime}$. The analyzed data were the Open Data collected by\nthe CMS detector in proton-proton collisions at the LHC in 2012 and correspond\nto an integrated luminosity of 11.6 fb$^{-1}$ at $\\sqrt{s} = $ 8 TeV. One\nbenchmark scenario the light vector was used for interpreting the data, based\non a simplified model so called the mono-Z$^{\\prime}$ model. No evidence of\ndark fermion candidates was found, 95$\\%$ confidence level limits have been set\non both Z$^{\\prime}$ and dark fermion masses.",
        "date": "2023-04-19",
        "doi": "http://dx.doi.org/10.1088/1674-1137/ad20d5",
        "title": "Search for the production of dark fermion candidates in association with\n  heavy neutral gauge boson decaying to dimuon in proton-proton collisions at\n  $\\sqrt{s} = 8$ TeV using the CMS open data",
        "url": "http://arxiv.org/abs/2304.09483v4"
    },
    {
        "abstract": "Precise measurements of the energy of jets emerging from particle collisions\nat the LHC are essential for a vast majority of physics searches at the CMS\nexperiment. In this study, we leverage well-established deep learning models\nfor point clouds and CMS open data to improve the energy calibration of\nparticle jets. To enable production-ready machine learning based jet energy\ncalibration an end-to-end pipeline is built on the Kubeflow cloud platform. The\npipeline allowed us to scale up our hyperparameter tuning experiments on cloud\nresources, and serve optimal models as REST endpoints. We present the results\nof the parameter tuning process and analyze the performance of the served\nmodels in terms of inference time and overhead, providing insights for future\nwork in this direction. The study also demonstrates improvements in both flavor\ndependence and resolution of the energy response when compared to the standard\njet energy corrections baseline.",
        "date": "2023-08-24",
        "doi": "http://dx.doi.org/10.1007/s41781-023-00103-y",
        "title": "Jet energy calibration with deep learning as a Kubeflow pipeline",
        "url": "http://arxiv.org/abs/2308.12724v2"
    },
    {
        "abstract": "This study aims to improve the performance of event classification in\ncollider physics by introducing a pre-training strategy. Event classification\nis a typical problem in collider physics, where the goal is to distinguish the\nsignal events of interest from background events as much as possible to search\nfor new phenomena in nature. A pre-training strategy with feasibility to\nefficiently train the target event classification using a small amount of\ntraining data has been proposed. Real particle collision data were used in the\npre-training phase as a novelty, where a self-supervised learning technique to\nhandle the unlabeled data was employed. The ability to use real data in the\npre-training phase eliminates the need to generate a large amount of training\ndata by simulation and mitigates bias in the choice of physics processes in the\ntraining data. Our experiments using CMS open data confirmed that high event\nclassification performance can be achieved by introducing a pre-trained model.\nThis pre-training strategy provides a potential approach to save computational\nresources for future collider experiments and introduces a foundation model for\nevent classification.",
        "date": "2023-12-12",
        "doi": "http://arxiv.org/abs/2312.06909v1",
        "title": "Pre-training strategy using real particle collision data for event\n  classification in collider physics",
        "url": "http://arxiv.org/abs/2312.06909v1"
    },
    {
        "abstract": "This note summarizes the lectures given in the tutorial session of the\nIntroduction to the Terascale school at DESY on March 2023. The target audience\nare advanced bachelor and master physics students. The tutorial aims to best\nprepare the students for starting an LHC experimental physics thesis. The cross\nsection of the top quark pair production is detailed alongside with the\nreconstruction of the invariant masses of the top quark as well as of the $W$\nand $Z$ bosons. The tutorial uses ideas and CMS open data files from the CMS\nHEP Tutorial written by C. Sander and A. Schmidt, but is entirely rewritten so\nthat it can be run in Google Colab Cloud in a columnar style of analysis with\npython. In addition, a minimal C/C++ version of a simple event-loop analysis\nrelying on ROOT is exampled. The code is kept as short as possible with\nemphasis on the transparency of the analysis steps, rather than the elegance of\nthe software, having in mind that the students will in any case need to rewrite\ntheir own custom analysis framework.",
        "date": "2024-03-13",
        "doi": "http://arxiv.org/abs/2403.08907v1",
        "title": "The terascale tutorial",
        "url": "http://arxiv.org/abs/2403.08907v1"
    },
    {
        "abstract": "This study presents a novel method for the definition of signal regions in\nsearches for new physics at collider experiments, specifically those conducted\nat CERN's Large Hadron Collider. By leveraging multi-dimensional histograms\nwith precise arithmetic and utilizing the SparkDensityTree library, it is\npossible to identify high-density regions within the available phase space,\npotentially improving sensitivity to very small signals. Inspired by an ongoing\nsearch for dark mesons at the ATLAS experiment, CMS open data is used for this\nproof-of-concept intentionally targeting an already excluded signal. Several\nsignal regions are defined based on density estimates of signal and background.\nThese preliminary regions align well with the physical properties of the signal\nwhile effectively rejecting background events. While not explored in this work,\nthis method is also scalable, which makes it ideal for large datasets such as\nthose expected at the high-luminosity upgrade of the LHC. Finally, this method\nis flexible and can be easily extended, promising a boost to the signal region\ndefinition process for new physics searches at colliders.",
        "date": "2024-04-05",
        "doi": "http://arxiv.org/abs/2404.04138v1",
        "title": "Sparks in the Dark",
        "url": "http://arxiv.org/abs/2404.04138v1"
    },
    {
        "abstract": "At high energy physics experiments, processing billions of records of\nstructured numerical data from collider events to a few statistical summaries\nis a common task. The data processing is typically more complex than standard\nquery languages allow, such that custom numerical codes are used. At present,\nthese codes mostly operate on individual event records and are parallelized in\nmulti-step data reduction workflows using batch jobs across CPU farms. Based on\na simplified top quark pair analysis with CMS Open Data, we demonstrate that it\nis possible to carry out significant parts of a collider analysis at a rate of\naround a million events per second on a single multicore server with optional\nGPU acceleration. This is achieved by representing HEP event data as\nmemory-mappable sparse arrays of columns, and by expressing common analysis\noperations as kernels that can be used to process the event data in parallel.\nWe find that only a small number of relatively simple functional kernels are\nneeded for a generic HEP analysis. The approach based on columnar processing of\ndata could speed up and simplify the cycle for delivering physics results at\nHEP experiments. We release the \\texttt{hepaccelerate} prototype library as a\ndemonstrator of such methods.",
        "date": "2019-06-14",
        "doi": "http://arxiv.org/abs/1906.06242v2",
        "title": "Processing Columnar Collider Data with GPU-Accelerated Kernels",
        "url": "http://arxiv.org/abs/1906.06242v2"
    },
    {
        "abstract": "Jets of hadrons produced at high-energy colliders provide experimental access\nto the dynamics of asymptotically free quarks and gluons and their confinement\ninto hadrons. In this paper, we show that the high energies of the Large Hadron\nCollider (LHC), together with the exceptional resolution of its detectors,\nallow multipoint correlation functions of energy flow operators to be directly\nmeasured within jets for the first time. Using Open Data from the CMS\nexperiment, we show that reformulating jet substructure in terms of these\ncorrelators provides new ways of probing the dynamics of QCD jets, which\nenables direct imaging of the confining transition to free hadrons as well as\nprecision measurements of the scaling properties and interactions of quarks and\ngluons. This opens a new era in our understanding of jet substructure and\nillustrates the immense unexploited potential of high-quality LHC data sets for\nelucidating the dynamics of QCD.",
        "date": "2022-01-19",
        "doi": "http://dx.doi.org/10.1103/PhysRevLett.130.051901",
        "title": "Analyzing N-point Energy Correlators Inside Jets with CMS Open Data",
        "url": "http://arxiv.org/abs/2201.07800v3"
    },
    {
        "abstract": "The remarkably high energies of the Large Hadron Collider (LHC) have allowed\nfor the first measurements of the shapes and scalings of multi-point\ncorrelators of energy flow operators, $\\langle \\Psi | \\mathcal{E}(\\vec n_1)\n\\mathcal{E}(\\vec n_2) \\cdots \\mathcal{E}(\\vec n_k) |\\Psi \\rangle$, providing\nnew insights into the Lorentzian dynamics of quantum chromodynamics (QCD). In\nthis Letter, we use recent advances in effective field theory to derive a\nrigorous factorization theorem for the light-ray density matrix, $\\rho=\n|\\Psi\\rangle \\langle \\Psi |$, inside high transverse momentum jets at the LHC.\nUsing the light-ray operator product expansion, the scaling behavior of\nmulti-point correlators can be computed from the expectation value of the\ntwist-2 spin-$J$ light-ray operators, $\\mathbb{O}^{[J]}$, in this state,\n$\\text{Tr}[ \\rho ~\\mathbb{O}^{[J]} ]$. We compute the light-ray density matrix\nat next-to-leading order, and combine this with results for the next-to-leading\nlogarithmic scaling behavior of the correlators up to six-points, comparing\nwith CMS Open Data. This theoretical accuracy allows us to resolve the quantum\nscaling dimensions of QCD light-ray operators inside jets at the LHC. Our\nfactorization theorem for the light-ray density matrix at the LHC completes the\nlink between recent developments in the study of energy correlators and LHC\nphenomenology, opening the door to a wide variety of precision jet substructure\nstudies.",
        "date": "2022-05-06",
        "doi": "http://arxiv.org/abs/2205.03414v1",
        "title": "Conformal Colliders Meet the LHC",
        "url": "http://arxiv.org/abs/2205.03414v1"
    },
    {
        "abstract": "We study quark and gluon jets separately using public collider data from the\nCMS experiment. Our analysis is based on 2.3/fb of proton-proton collisions at\n7 TeV, collected at the Large Hadron Collider in 2011. We define two\nnon-overlapping samples via a pseudorapidity cut -- central jets with |eta| <\n0.65 and forward jets with |eta| > 0.65 -- and employ jet topic modeling to\nextract individual distributions for the maximally separable categories. Under\ncertain assumptions, such as sample independence and mutual irreducibility,\nthese categories correspond to \"quark\" and \"gluon\" jets, as given by a recently\nproposed operational definition. We consider a number of different methods for\nextracting reducibility factors from the central and forward datasets, from\nwhich the fractions of quark jets in each sample can be determined. The\ngreatest stability and robustness to statistical uncertainties is achieved by a\nnovel method based on parametrizing the endpoints of a receiver operating\ncharacteristic (ROC) curve. To mitigate detector effects, which would otherwise\ninduce unphysical differences between central and forward jets, we use the\nOmniFold method to perform central value unfolding. As a demonstration of the\npower of this method, we extract the intrinsic dimensionality of the quark and\ngluon jet samples, which exhibit Casimir scaling, as expected from the\nstrongly-ordered limit. To our knowledge, this work is the first application of\nfull phase space unfolding to real collider data, and one of the first\napplications of topic modeling to extract separate quark and gluon\ndistributions at the LHC.",
        "date": "2022-05-09",
        "doi": "http://dx.doi.org/10.1103/PhysRevD.106.094021",
        "title": "Disentangling Quarks and Gluons with CMS Open Data",
        "url": "http://arxiv.org/abs/2205.04459v2"
    },
    {
        "abstract": "The microscopic dynamics of particle collisions is imprinted into the\nstatistical properties of asymptotic energy flux, much like the dynamics of\ninflation is imprinted into the cosmic microwave background. This energy flux\nis characterized by correlation functions $\\langle \\mathcal{E}(\\vec n_1)\\cdots\n\\mathcal{E}(\\vec n_k) \\rangle$ of energy flow operators $ \\mathcal{E}(\\vec n)$.\nThere has been significant recent progress in studying energy flux, including\nthe calculation of multi-point correlation functions and their direct\nmeasurement inside high-energy jets at the Large Hadron Collider (LHC). In this\npaper, we build on these advances by defining a notion of \"celestial\nnon-gaussianity\" as a ratio of the three-point function to a product of\ntwo-point functions. We show that this celestial non-gaussianity is under\nperturbative control within jets at the LHC, allowing us to cleanly access the\nnon-gaussian interactions of quarks and gluons. We find good agreement between\nperturbative calculations of the non-gaussianity and a charged-particle-based\nanalysis using CMS Open Data, and we observe a strong non-gaussianity peaked in\nthe \"flattened triangle\" regime. The ability to robustly study three-point\ncorrelations is a significant step in advancing our understanding of jet\nsubstructure at the LHC. We anticipate that the celestial non-gaussianity, and\nits generalizations, will play an important role in the development of\nhigher-order parton showers simulations and in the hunt for ever more subtle\nsignals of potential new physics within jets.",
        "date": "2022-05-05",
        "doi": "http://dx.doi.org/10.1007/JHEP07(2022)146",
        "title": "Non-Gaussianities in Collider Energy Flux",
        "url": "http://arxiv.org/abs/2205.02857v2"
    }
]